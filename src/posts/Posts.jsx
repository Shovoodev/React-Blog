import Post from '../post/Post'
import './posts.css'

export default function Posts()  {
  return (
    <div className='posts'>
        <Post title="ChatGPT gets better marks than students in some university courses"
         description="ChatGPT may be as good as or better than students at assessments in around a quarter of university courses. However, this generally only applies to questions with a clear answer that require memory recall, rather than critical analysis.

         Yasir Zaki and his team at New York University Abu Dhabi in the United Arab Emirates contacted colleagues in other departments asking them to provide assessment questions from courses taught at the university, including computer science, psychology, political science and business.
         
         These colleagues also provided real student answers to the questions. The questions were then run through the artificial intelligence chatbot ChatGPT, which supplied its own responses.
         
         Next, both sets of responses were sent to a team of graders. “These graders were not made aware of the sources of these answers, nor were they aware of the purpose of the grading,” says Zaki.
         
         In nine out of the 32 courses surveyed, ChatGPT’s answers were rated as good as or better than those of students. At times, its answers were substantially better. For example, it achieved almost double the average score of students when answering questions from a course called Introduction to Public Policy.
         
         “ChatGPT performed much better on questions that required information recall, but performed poorly on questions which required critical analysis,” says Zaki."
          image="https://images.yourstory.com/cs/2/ba6b0930e8cd11edbf1c2f9de7fdeb77/FREE2-1684909018438.png?w=1152&fm=auto&ar=2:1&mode=crop&crop=faces"/>
          <Post title="ChatGPT gets better marks than students in some university courses"
         description="ChatGPT may be as good as or better than students at assessments in around a quarter of university courses. However, this generally only applies to questions with a clear answer that require memory recall, rather than critical analysis.

         Yasir Zaki and his team at New York University Abu Dhabi in the United Arab Emirates contacted colleagues in other departments asking them to provide assessment questions from courses taught at the university, including computer science, psychology, political science and business.
         
         These colleagues also provided real student answers to the questions. The questions were then run through the artificial intelligence chatbot ChatGPT, which supplied its own responses.
         
         Next, both sets of responses were sent to a team of graders. “These graders were not made aware of the sources of these answers, nor were they aware of the purpose of the grading,” says Zaki.
         
         In nine out of the 32 courses surveyed, ChatGPT’s answers were rated as good as or better than those of students. At times, its answers were substantially better. For example, it achieved almost double the average score of students when answering questions from a course called Introduction to Public Policy.
         
         “ChatGPT performed much better on questions that required information recall, but performed poorly on questions which required critical analysis,” says Zaki."
          image="https://images.yourstory.com/cs/2/ba6b0930e8cd11edbf1c2f9de7fdeb77/FREE2-1684909018438.png?w=1152&fm=auto&ar=2:1&mode=crop&crop=faces"/>
          <Post title="ChatGPT gets better marks than students in some university courses"
         description="ChatGPT may be as good as or better than students at assessments in around a quarter of university courses. However, this generally only applies to questions with a clear answer that require memory recall, rather than critical analysis.

         Yasir Zaki and his team at New York University Abu Dhabi in the United Arab Emirates contacted colleagues in other departments asking them to provide assessment questions from courses taught at the university, including computer science, psychology, political science and business.
         
         These colleagues also provided real student answers to the questions. The questions were then run through the artificial intelligence chatbot ChatGPT, which supplied its own responses.
         
         Next, both sets of responses were sent to a team of graders. “These graders were not made aware of the sources of these answers, nor were they aware of the purpose of the grading,” says Zaki.
         
         In nine out of the 32 courses surveyed, ChatGPT’s answers were rated as good as or better than those of students. At times, its answers were substantially better. For example, it achieved almost double the average score of students when answering questions from a course called Introduction to Public Policy.
         
         “ChatGPT performed much better on questions that required information recall, but performed poorly on questions which required critical analysis,” says Zaki."
          image="https://images.yourstory.com/cs/2/ba6b0930e8cd11edbf1c2f9de7fdeb77/FREE2-1684909018438.png?w=1152&fm=auto&ar=2:1&mode=crop&crop=faces"/>
          <Post title="ChatGPT gets better marks than students in some university courses"
         description="ChatGPT may be as good as or better than students at assessments in around a quarter of university courses. However, this generally only applies to questions with a clear answer that require memory recall, rather than critical analysis.

         Yasir Zaki and his team at New York University Abu Dhabi in the United Arab Emirates contacted colleagues in other departments asking them to provide assessment questions from courses taught at the university, including computer science, psychology, political science and business.
         
         These colleagues also provided real student answers to the questions. The questions were then run through the artificial intelligence chatbot ChatGPT, which supplied its own responses.
         
         Next, both sets of responses were sent to a team of graders. “These graders were not made aware of the sources of these answers, nor were they aware of the purpose of the grading,” says Zaki.
         
         In nine out of the 32 courses surveyed, ChatGPT’s answers were rated as good as or better than those of students. At times, its answers were substantially better. For example, it achieved almost double the average score of students when answering questions from a course called Introduction to Public Policy.
         
         “ChatGPT performed much better on questions that required information recall, but performed poorly on questions which required critical analysis,” says Zaki."
          image="https://images.yourstory.com/cs/2/ba6b0930e8cd11edbf1c2f9de7fdeb77/FREE2-1684909018438.png?w=1152&fm=auto&ar=2:1&mode=crop&crop=faces"/>
          
    </div>
  )
}
